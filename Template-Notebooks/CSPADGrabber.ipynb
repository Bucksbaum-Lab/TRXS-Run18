{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment and path specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the experiment for analysis\n",
    "experiment='cxilu9218'\n",
    "runNumber = 91\n",
    "\n",
    "# Set the installation and output path\n",
    "import os\n",
    "os.environ['INSTALLPATH']= '/cds/home/i/igabalsk/TRXS-Run18'\n",
    "os.environ['OUTPUTPATH']= '/cds/data/psdm/%s/%s/scratch' % (experiment[0:3],experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic iPython command to enable plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load in the pythonBatchMagic library\n",
    "import sys\n",
    "print os.environ['INSTALLPATH']+'/Libraries/pythonBatchMagic'\n",
    "sys.path.insert(0, os.environ['INSTALLPATH']+'/Libraries/pythonBatchMagic')\n",
    "from pythonBatchMagic import *\n",
    "# Determine current user\n",
    "currentUser, error = unixCMD(\"echo $USER\")\n",
    "print(currentUser)\n",
    "os.environ['RESULTSPATH']= ('/cds/data/psdm/%s/%s/results/%s' % (experiment[0:3],experiment,currentUser)).strip()\n",
    "if not os.path.exists(os.environ['RESULTSPATH']):\n",
    "    os.mkdir(os.environ['RESULTSPATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging the batch queue to quickly grab detector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.environ['INSTALLPATH']+'/Libraries/LCLS')\n",
    "from LCLSdefault import *\n",
    "\n",
    "sys.path.insert(0, os.environ['INSTALLPATH']+'/Libraries/mattsLibraries')\n",
    "from picklez import *\n",
    "\n",
    "# Load in the get data library\n",
    "from dataAnalysis import *\n",
    "\n",
    "# Load in the batch library for lcls\n",
    "from lclsBatch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pointData = load_obj( os.environ['RESULTSPATH']+'/pointData-run-%d' % runNumber )\n",
    "pointData = load_obj('/cds/data/psdm/cxi/cxilu9218/results/mrware/pointData-run-%d' % runNumber)\n",
    "\n",
    "def dropEmpty(pointData):\n",
    "\n",
    "    filledBin = (pointData['seconds'] > 0)    \n",
    "\n",
    "    for key in pointData.keys():\n",
    "        pointData[key]=pointData[key][filledBin] \n",
    "        \n",
    "    return pointData\n",
    "\n",
    "def dropNaN(pointData):\n",
    "    goodBin = np.ones(pointData['seconds'].shape, dtype=bool)\n",
    "    for key in pointData.keys():\n",
    "        if not pointData[key].dtype==np.dtype(object) and pointData[key].shape==pointData['seconds'].shape:\n",
    "            goodBin = goodBin & ~np.isnan(pointData[key])\n",
    "    for key in pointData.keys():\n",
    "        pointData[key]=pointData[key][goodBin]\n",
    "    return pointData\n",
    "print len(pointData['seconds'])\n",
    "pointData_masked = dropNaN(dropEmpty(pointData))\n",
    "print 'Number of good shots: ', len(pointData_masked['seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram of result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detArrays = pointData\n",
    "print detArrays.keys()\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1)\n",
    "ax2.hist(detArrays['uvint1'], bins=100,normed=False, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in CSPAD via batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify good idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodIdx = runFilter( pointData , filterOn=['ttfltpos','uvint','uvint1'], maddevs=3 ).astype(bool)\n",
    "gooseIdx = ~pointData['laserOn']\n",
    "goodIdx = goodIdx & pointData['laserOn'] & pointData['xrayOn']\n",
    "print 'Number of good shots: ', len(goodIdx[goodIdx==True])\n",
    "print 'Number of goose shots: ', len(gooseIdx[gooseIdx==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now generate time delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrated timetool for LU92\n",
    "TTPoly = np.array([2.95684259e-06, -1.43969413e-03]) \n",
    "\n",
    "TTFltPos = pointData['ttfltpos']\n",
    "TTCorrFltPos = TTPoly[0]*TTFltPos+TTPoly[1]\n",
    "TTTime = 1e3*TTCorrFltPos - 1e9/3e8*2*(pointData['stageencoder']-56.35)\n",
    "\n",
    "# NOTE: This is a placeholder, and should be removed on runs with timetool data\n",
    "# TTTime = np.zeros(pointData['xrayEnergy'].shape)\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1)\n",
    "ax2.hist(TTTime[goodIdx], bins=100,normed=False, alpha=1)\n",
    "ax2.set_xlabel('Delay (ps)')\n",
    "ax2.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in all images\n",
    "## If you just want to look at all the images at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tagList = []\n",
    "# size_slice = int(len(goodIdx[goodIdx==True])/20)\n",
    "# print size_slice\n",
    "# for idx in range(20):\n",
    "#     filteredSeconds = pointData['seconds'][goodIdx][0+size_slice*idx:size_slice+size_slice*idx]\n",
    "#     filteredNanoseconds = pointData['nanoseconds'][goodIdx][0+size_slice*idx:size_slice+size_slice*idx]\n",
    "#     filteredFiducials = pointData['fiducials'][goodIdx][0+size_slice*idx:size_slice+size_slice*idx]\n",
    "#     tagList.append( {'seconds':filteredSeconds, 'nanoseconds':filteredNanoseconds, 'fiducials':filteredFiducials} )\n",
    "\n",
    "# # batchThreads = batchCSPADGrabber (tagList, experiment=experiment, runNumber=runNumber, detType='Jungfrau')\n",
    "# batchThreads = batchCSPADMVGrabber (tagList, experiment=experiment, runNumber=runNumber, detType='Jungfrau')\n",
    "# timebins=np.arange(10)\n",
    "# batchThreads.Queue = 'psanaq'\n",
    "# batchThreads.RunType = 'mpirun python2'\n",
    "# batchThreads.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.unique(TTTime)\n",
    "print np.unique(pointData['stageencoder'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in timebinned CSPAD\n",
    "## If you want to timebin your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timebins = np.arange( -1.5,1.5,.03 )\n",
    "# timebins are in picoseconds\n",
    "# timebins = np.arange( 2.,5.5,.03 ) \n",
    "# timebins = np.arange( -2, 2, .05 )\n",
    "# timebins = np.array([-1.25,0.75])\n",
    "# timebins = np.unique(TTTime)\n",
    "def rebin_stage_positions(stage_positions):\n",
    "    unique = np.sort(np.unique(stage_positions))\n",
    "    unique_binned = []\n",
    "    for i, val in enumerate(unique[:-1]):\n",
    "        if unique[i+1]-unique[i]>0.004:\n",
    "            unique_binned.append(unique[i])\n",
    "    unique_binned.append(unique[-1])\n",
    "    return np.array(unique_binned)\n",
    "timebins = -1e9/3e8*2*(rebin_stage_positions(pointData['stageencoder'])-56.35)\n",
    "print 'Number of timebins: ', len(timebins)\n",
    "# dt = timebins[1]-timebins[0]\n",
    "dt = np.min(np.diff(timebins))\n",
    "print 'dt (ps): ',dt\n",
    "\n",
    "# first timebin is for goose trigger events\n",
    "# set to very large negative number (laser definitely off)\n",
    "timebins = np.concatenate((np.array([-100]),timebins))\n",
    "NT = timebins.size\n",
    "\n",
    "# print np.around(timebins,3)\n",
    "# print np.sort(1e9/3e8*2*(rebin_stage_positions(pointData['stageencoder'])-56.35))\n",
    "\n",
    "tagList = []\n",
    "for idx, t in enumerate(timebins):\n",
    "    if idx>0 and idx<len(timebins)-1:\n",
    "        dt_plus = (timebins[idx+1]-timebins[idx])/2\n",
    "        dt_minus = (timebins[idx]-timebins[idx-1])/2\n",
    "    elif idx==0:\n",
    "        dt_plus = (timebins[idx+1]-timebins[idx])/2\n",
    "        dt_minus = 1.0\n",
    "    elif idx==len(timebins)-1:\n",
    "        dt_plus = 1.0\n",
    "        dt_minus = (timebins[idx]-timebins[idx-1])/2\n",
    "    tIndex = (TTTime >= t-dt_minus)&(TTTime < t+dt_plus)\n",
    "    allIndex = tIndex & goodIdx\n",
    "    filteredSeconds = pointData['seconds'][allIndex]\n",
    "    filteredNanoseconds = pointData['nanoseconds'][allIndex]\n",
    "    filteredFiducials = pointData['fiducials'][allIndex]\n",
    "    tagList.append( {'seconds':filteredSeconds, 'nanoseconds':filteredNanoseconds, 'fiducials':filteredFiducials} )\n",
    "\n",
    "# # batchThreads = batchCSPADGrabber (tagList, experiment=experiment, runNumber=runNumber, detType='Jungfrau')\n",
    "# batchThreads = batchCSPADMVGrabber (tagList, experiment=experiment, runNumber=runNumber, detType='Jungfrau')\n",
    "\n",
    "# batchThreads.Queue = 'psanaq'\n",
    "# batchThreads.RunType = 'mpirun python2'\n",
    "# batchThreads.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print batchThreads.status\n",
    "stdoutdata, stderrdata = bjobs()\n",
    "print stdoutdata\n",
    "print stderrdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kill threads if they die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchThreads.requestStop()\n",
    "time.sleep(5)\n",
    "stdoutdata, stderrdata = bkill(killAll=True)\n",
    "print stdoutdata\n",
    "print stderrdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save resulting CSPAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchThreads.gather()\n",
    "CSPAD = batchThreads.CSPAD[:,:,:,1:]\n",
    "variance = batchThreads.variance[:,:,:,1:]\n",
    "counts = batchThreads.counts[1:]\n",
    "timebins_goose = timebins[0:1]\n",
    "CSPAD_goose = batchThreads.CSPAD[:,:,:,0]\n",
    "variance_goose = batchThreads.variance[:,:,:,0]\n",
    "counts_goose = batchThreads.counts[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "import h5py\n",
    "\n",
    "# save as numpy array\n",
    "np.save(os.environ['RESULTSPATH']+'/timebins-run-%d' % runNumber ,timebins)\n",
    "np.save(os.environ['RESULTSPATH']+'/CSPAD-run-%d' % runNumber  , CSPAD)\n",
    "np.save(os.environ['RESULTSPATH']+'/variance-run-%d' %  runNumber , variance)\n",
    "np.save(os.environ['RESULTSPATH']+'/counts-run-%d' % runNumber  , counts)\n",
    "np.save(os.environ['RESULTSPATH']+'/timebins_goose-run-%d' % runNumber ,timebins_goose)\n",
    "np.save(os.environ['RESULTSPATH']+'/CSPAD_goose-run-%d' % runNumber  , CSPAD_goose)\n",
    "np.save(os.environ['RESULTSPATH']+'/variance_goose-run-%d' %  runNumber , variance_goose)\n",
    "np.save(os.environ['RESULTSPATH']+'/counts_goose-run-%d' % runNumber  , counts_goose)\n",
    "\n",
    "# save as .mat\n",
    "# filename = os.environ['RESULTSPATH']+'/timebinned-detector-images-run-%d' % runNumber\n",
    "# mdict = {'timebins':timebins,'CSPAD':CSPAD,'variance':variance,'counts':counts}\n",
    "# savemat(filename, mdict)\n",
    "\n",
    "# save as .h5\n",
    "filename = os.environ['RESULTSPATH']+'/timebinned-detector-images-run-%d.h5' % runNumber\n",
    "with h5py.File(filename, 'w') as hf:\n",
    "    hf.create_dataset(\"timebins\",  data=timebins)\n",
    "    hf.create_dataset(\"CSPAD\",  data=CSPAD)\n",
    "    hf.create_dataset(\"variance\",  data=variance)\n",
    "    hf.create_dataset(\"counts\",  data=counts)\n",
    "    hf.create_dataset(\"timebins_goose\",  data=timebins_goose)\n",
    "    hf.create_dataset(\"CSPAD_goose\",  data=CSPAD_goose)\n",
    "    hf.create_dataset(\"variance_goose\",  data=variance_goose)\n",
    "    hf.create_dataset(\"counts_goose\",  data=counts_goose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot CSPAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional code if timebinned frames are already saved\n",
    "timebins = np.load(os.environ['RESULTSPATH']+'/timebins-run-%d.npy' % runNumber )\n",
    "CSPAD = np.load(os.environ['RESULTSPATH']+'/CSPAD-run-%d.npy' % runNumber)\n",
    "variance = np.load(os.environ['RESULTSPATH']+'/variance-run-%d.npy' % runNumber)\n",
    "counts = np.load(os.environ['RESULTSPATH']+'/counts-run-%d.npy' % runNumber)\n",
    "timebins_goose = np.load(os.environ['RESULTSPATH']+'/timebins_goose-run-%d.npy' % runNumber )\n",
    "CSPAD_goose = np.load(os.environ['RESULTSPATH']+'/CSPAD_goose-run-%d.npy' % runNumber)\n",
    "variance_goose = np.load(os.environ['RESULTSPATH']+'/variance_goose-run-%d.npy' % runNumber)\n",
    "counts_goose = np.load(os.environ['RESULTSPATH']+'/counts_goose-run-%d.npy' % runNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(CSPAD.shape[-1]):\n",
    "    m = np.mean(CSPAD[:,:,:,i])\n",
    "    if not np.isnan(m):\n",
    "        print i, np.mean(CSPAD[:,:,:,i]), counts[i][0], timebins[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from plotStyles import *\n",
    "\n",
    "def plotCSPAD( cspad , x , y, cspadMask=None, zLims = None, divergent=False, NTILE=8 ):\n",
    "    figOpts = {'xLims':[-1e5,1e5],'yLims':[-1e5,1e5],'divergent':divergent, 'xIn':3, 'yIn':3*11.5/14.5}\n",
    "    \n",
    "    if zLims is not None:\n",
    "        figOpts['zLims'] = zLims\n",
    "    \n",
    "    for iTile in range(NTILE):\n",
    "    \n",
    "        if cspadMask is not None:\n",
    "            cspadTile = cspad[iTile,:,:]\n",
    "            tileMask = ~cspadMask[iTile,:,:]\n",
    "            cspadTile[tileMask] = 0\n",
    "        \n",
    "        if iTile == 0:\n",
    "            newFigure = True\n",
    "        else:\n",
    "            newFigure = False\n",
    "            \n",
    "        clear_output()\n",
    "        colorPlot( x[iTile,:,:], y[iTile,:,:], cspadTile , newFigure=newFigure, **figOpts);\n",
    "\n",
    "\n",
    "x,y = CSPADgeometry(detType='Jungfrau', run=runNumber, experiment=experiment)\n",
    "\n",
    "# cspadMask = createMask(experiment=experiment, run=runNumber, detType='Jungfrau').astype(bool)\n",
    "cspadMask = np.ones_like(x).astype(bool)\n",
    "print(cspadMask.shape)\n",
    "\n",
    "print CSPAD.shape\n",
    "CSPADbinned = CSPAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSPADbinned = np.copy(CSPAD)\n",
    "# CSPADbinned[CSPADbinned>2000]=0\n",
    "\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "sigma = 10\n",
    "\n",
    "CSPADblurred = np.zeros(CSPAD.shape)\n",
    "CSPADbinned[CSPADbinned>50]=0\n",
    "for i in range(CSPAD.shape[-1]):\n",
    "    if not np.isnan(counts[i][0]):\n",
    "        for j, tile in enumerate(CSPADbinned[:,:,:,i]):\n",
    "            CSPADblurred[j,:,:,i] = gaussian_filter(tile, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSPADsummed = np.nanmean(CSPADbinned, axis=-1)\n",
    "plotCSPAD( CSPADsummed, x , y , zLims=[0,1.5],\n",
    "          cspadMask=cspadMask, divergent=False, NTILE=8)\n",
    "# plt.savefig('sf6_run12.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = CSPADbinned[:,:,:,12]\n",
    "print np.mean(frame), np.std(frame)\n",
    "print len(frame[frame>0])*0.1/len(frame.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print '{0:<5} {1:>5} {2:>8} {3:>8} {4:>8}'.format('Index','Count','Sum','Median','Variance')\n",
    "for i in range(CSPAD.shape[-1]):\n",
    "    if counts[i][0]>0:\n",
    "        vals = (i, counts[i][0], round(np.sum(CSPAD[:,:,:,i])),round(np.median(CSPAD[:,:,:,i]),4), round(np.var(CSPAD[:,:,:,i]),4))\n",
    "        print '{0:<5} {1:>5} {2:>8} {3:>8} {4:>8}'.format(*vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = CSPADgeometry(detType='Jungfrau', run=runNumber, experiment=experiment)\n",
    "\n",
    "# filename = os.environ['RESULTSPATH']+'/detector-geometry'\n",
    "# mdict = {'x':x,'y':y}\n",
    "# savemat(filename, mdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "fig2, ax2 = plt.subplots(1, 1)\n",
    "ax2.hist(TTTime[goodIdx], bins=100,normed=False, alpha=1)\n",
    "ax2.set_xlabel('Delay (ps)')\n",
    "ax2.set_ylabel('Counts')\n",
    "for i,ibin in enumerate(timebins[1:-1]):\n",
    "    plt.axvline(x=timebins[i+1]+(timebins[i+2]-timebins[i+1])/2., color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCLS-I py2",
   "language": "python",
   "name": "ana1-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
